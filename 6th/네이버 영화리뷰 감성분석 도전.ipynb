{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75c4e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0257ad0",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3533638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3) (50000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec651847",
   "metadata": {},
   "source": [
    "* 데이터의 중복 제거\n",
    "* NaN 결측치 제거\n",
    "* 한국어 토크나이저로 토큰화\n",
    "* 불용어(Stopwords) 제거\n",
    "* 사전word_to_index 구성\n",
    "* 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "* X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd2697",
   "metadata": {},
   "source": [
    "## 2) 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2334ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']\n",
    "\n",
    "\n",
    "def preprocess(texts):\n",
    "    # 토큰화 및 불용어 제거\n",
    "    tokens = [token for text in texts for token in tokenizer.morphs(text) if token not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(tokens, num_words=None):\n",
    "    # 사전 구성\n",
    "    counter = Counter(tokens)\n",
    "    vocab = {\n",
    "        '<PAD>': 0,  # 패딩용 단어\n",
    "        '<BOS>': 1,  # 문장의 시작지점\n",
    "        '<UNK>': 2   # 사전에 없는(Unknown) 단어\n",
    "    }\n",
    "    if num_words:\n",
    "        most_common = counter.most_common(num_words - len(vocab))\n",
    "    else:\n",
    "        most_common = counter.most_common()\n",
    "    \n",
    "    for i, (word, _) in enumerate(most_common, start=len(vocab)):\n",
    "        vocab[word] = i\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def texts_to_sequences(texts, word_to_index):\n",
    "    # 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "    sequences = [[word_to_index.get(token, 0) for token in tokenizer.morphs(text)] for text in texts]\n",
    "    return sequences\n",
    "\n",
    "def load_data(train_data, test_data, num_words=None):\n",
    "    # 1. 중복 제거 및 NaN 결측치 제거\n",
    "    train_data = train_data.drop_duplicates().dropna().reset_index(drop=True)\n",
    "    test_data = test_data.drop_duplicates().dropna().reset_index(drop=True)\n",
    "    \n",
    "    # 2. 데이터 분리\n",
    "    X_train = train_data['document'].tolist()\n",
    "    y_train = train_data['label'].tolist()\n",
    "    X_test = test_data['document'].tolist()\n",
    "    y_test = test_data['label'].tolist()\n",
    "\n",
    "    # 3. 텍스트 전처리 (토큰화 및 불용어 제거)\n",
    "    train_tokens = preprocess(X_train)\n",
    "    test_tokens = preprocess(X_test)\n",
    "\n",
    "    # 4. 사전 구성\n",
    "    word_to_index = build_vocab(train_tokens, num_words)\n",
    "\n",
    "    # 5. 텍스트를 인덱스 시퀀스로 변환\n",
    "    X_train_seq = texts_to_sequences(X_train, word_to_index)\n",
    "    X_test_seq = texts_to_sequences(X_test, word_to_index)\n",
    "\n",
    "    return X_train_seq, np.array(y_train), X_test_seq, np.array(y_test), word_to_index\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data, num_words=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56ce5d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149995 49997\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test)) # 중복 제거 및 NaN 결측치 제거의 영향으로 판단됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7646eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<BOS>': 1,\n",
       " '<UNK>': 2,\n",
       " '.': 3,\n",
       " '영화': 4,\n",
       " '다': 5,\n",
       " '고': 6,\n",
       " '하': 7,\n",
       " '을': 8,\n",
       " '보': 9,\n",
       " '..': 10,\n",
       " '게': 11,\n",
       " ',': 12,\n",
       " '!': 13,\n",
       " '지': 14,\n",
       " '있': 15,\n",
       " '없': 16,\n",
       " '?': 17,\n",
       " '좋': 18,\n",
       " '나': 19,\n",
       " '었': 20,\n",
       " '만': 21,\n",
       " '는데': 22,\n",
       " '너무': 23,\n",
       " '봤': 24,\n",
       " '적': 25,\n",
       " '안': 26,\n",
       " '정말': 27,\n",
       " '로': 28,\n",
       " '음': 29,\n",
       " '것': 30,\n",
       " '아': 31,\n",
       " '네요': 32,\n",
       " '재밌': 33,\n",
       " '어': 34,\n",
       " '점': 35,\n",
       " '같': 36,\n",
       " '지만': 37,\n",
       " '진짜': 38,\n",
       " '했': 39,\n",
       " '에서': 40,\n",
       " '기': 41,\n",
       " '네': 42,\n",
       " '않': 43,\n",
       " '거': 44,\n",
       " '았': 45,\n",
       " '수': 46,\n",
       " '되': 47,\n",
       " '면': 48,\n",
       " 'ㅋㅋ': 49,\n",
       " '말': 50,\n",
       " '연기': 51,\n",
       " '인': 52,\n",
       " '최고': 53,\n",
       " '주': 54,\n",
       " '내': 55,\n",
       " '~': 56,\n",
       " '평점': 57,\n",
       " '이런': 58,\n",
       " '어요': 59,\n",
       " '던': 60,\n",
       " '할': 61,\n",
       " '왜': 62,\n",
       " '1': 63,\n",
       " '겠': 64,\n",
       " '해': 65,\n",
       " '스토리': 66,\n",
       " '습니다': 67,\n",
       " 'ㅋㅋㅋ': 68,\n",
       " '...': 69,\n",
       " '드라마': 70,\n",
       " '생각': 71,\n",
       " '아니': 72,\n",
       " '더': 73,\n",
       " '그': 74,\n",
       " '싶': 75,\n",
       " '사람': 76,\n",
       " '듯': 77,\n",
       " '감동': 78,\n",
       " '때': 79,\n",
       " '함': 80,\n",
       " '배우': 81,\n",
       " '본': 82,\n",
       " '까지': 83,\n",
       " '뭐': 84,\n",
       " '볼': 85,\n",
       " '알': 86,\n",
       " '만들': 87,\n",
       " '내용': 88,\n",
       " '감독': 89,\n",
       " '보다': 90,\n",
       " '라': 91,\n",
       " '재미': 92,\n",
       " '그냥': 93,\n",
       " '지루': 94,\n",
       " '시간': 95,\n",
       " '재미있': 96,\n",
       " '중': 97,\n",
       " '년': 98,\n",
       " '잼': 99,\n",
       " '10': 100,\n",
       " '재미없': 101,\n",
       " '였': 102,\n",
       " '쓰레기': 103,\n",
       " '사랑': 104,\n",
       " '못': 105,\n",
       " '냐': 106,\n",
       " '서': 107,\n",
       " '2': 108,\n",
       " '라고': 109,\n",
       " '야': 110,\n",
       " '니': 111,\n",
       " '면서': 112,\n",
       " '번': 113,\n",
       " '다시': 114,\n",
       " '나오': 115,\n",
       " '작품': 116,\n",
       " '이거': 117,\n",
       " '하나': 118,\n",
       " '줄': 119,\n",
       " '해서': 120,\n",
       " '개': 121,\n",
       " '남': 122,\n",
       " '정도': 123,\n",
       " '마지막': 124,\n",
       " '끝': 125,\n",
       " '이건': 126,\n",
       " '임': 127,\n",
       " '액션': 128,\n",
       " 'ㅋ': 129,\n",
       " '3': 130,\n",
       " '입니다': 131,\n",
       " '기대': 132,\n",
       " '건': 133,\n",
       " '완전': 134,\n",
       " '라는': 135,\n",
       " '분': 136,\n",
       " '다는': 137,\n",
       " '참': 138,\n",
       " '많': 139,\n",
       " '아깝': 140,\n",
       " '처음': 141,\n",
       " '장면': 142,\n",
       " '대': 143,\n",
       " '다가': 144,\n",
       " '으면': 145,\n",
       " '지금': 146,\n",
       " '모르': 147,\n",
       " '이렇게': 148,\n",
       " \"'\": 149,\n",
       " '편': 150,\n",
       " '일': 151,\n",
       " '이게': 152,\n",
       " '돈': 153,\n",
       " '최악': 154,\n",
       " '성': 155,\n",
       " '느낌': 156,\n",
       " '시': 157,\n",
       " '이야기': 158,\n",
       " '별로': 159,\n",
       " '된': 160,\n",
       " '봐도': 161,\n",
       " '님': 162,\n",
       " '어서': 163,\n",
       " '애': 164,\n",
       " '전': 165,\n",
       " 'ㅠㅠ': 166,\n",
       " '넘': 167,\n",
       " '인데': 168,\n",
       " '다고': 169,\n",
       " '이해': 170,\n",
       " '명작': 171,\n",
       " '^^': 172,\n",
       " '그리고': 173,\n",
       " '역시': 174,\n",
       " '난': 175,\n",
       " '여자': 176,\n",
       " '또': 177,\n",
       " '이상': 178,\n",
       " '걸': 179,\n",
       " '한국': 180,\n",
       " '에게': 181,\n",
       " '는지': 182,\n",
       " '많이': 183,\n",
       " '부터': 184,\n",
       " '만든': 185,\n",
       " '주인공': 186,\n",
       " '받': 187,\n",
       " '합니다': 188,\n",
       " '!!': 189,\n",
       " '두': 190,\n",
       " '우리': 191,\n",
       " '살': 192,\n",
       " '괜찮': 193,\n",
       " '길': 194,\n",
       " '엔': 195,\n",
       " '기억': 196,\n",
       " '한다': 197,\n",
       " 'ㅎㅎ': 198,\n",
       " '연출': 199,\n",
       " '때문': 200,\n",
       " '이나': 201,\n",
       " '요': 202,\n",
       " '저': 203,\n",
       " '재': 204,\n",
       " '꼭': 205,\n",
       " '랑': 206,\n",
       " '며': 207,\n",
       " '현실': 208,\n",
       " 'ㅡㅡ': 209,\n",
       " '긴': 210,\n",
       " '무슨': 211,\n",
       " '마음': 212,\n",
       " '내내': 213,\n",
       " '굿': 214,\n",
       " '결말': 215,\n",
       " '죽': 216,\n",
       " '남자': 217,\n",
       " '세요': 218,\n",
       " '전개': 219,\n",
       " '속': 220,\n",
       " '소재': 221,\n",
       " '짱': 222,\n",
       " '인생': 223,\n",
       " '공포': 224,\n",
       " '다른': 225,\n",
       " '아서': 226,\n",
       " '씨': 227,\n",
       " '~~': 228,\n",
       " '짜증': 229,\n",
       " '은데': 230,\n",
       " '아요': 231,\n",
       " '뿐': 232,\n",
       " '필요': 233,\n",
       " '별': 234,\n",
       " '유치': 235,\n",
       " '가장': 236,\n",
       " '음악': 237,\n",
       " ')': 238,\n",
       " '일본': 239,\n",
       " '낮': 240,\n",
       " '아이': 241,\n",
       " ';;': 242,\n",
       " '오': 243,\n",
       " '반전': 244,\n",
       " '매력': 245,\n",
       " '수준': 246,\n",
       " '다니': 247,\n",
       " '밋': 248,\n",
       " '웃': 249,\n",
       " '맞': 250,\n",
       " '인지': 251,\n",
       " '가슴': 252,\n",
       " '없이': 253,\n",
       " '원작': 254,\n",
       " '높': 255,\n",
       " 'ㄷ': 256,\n",
       " '인간': 257,\n",
       " '데': 258,\n",
       " 'ㅠ': 259,\n",
       " '(': 260,\n",
       " '노': 261,\n",
       " '만드': 262,\n",
       " '급': 263,\n",
       " '눈물': 264,\n",
       " '준': 265,\n",
       " '보여': 266,\n",
       " '용': 267,\n",
       " '찍': 268,\n",
       " '인가': 269,\n",
       " '을까': 270,\n",
       " '코미디': 271,\n",
       " '마': 272,\n",
       " '화': 273,\n",
       " '신': 274,\n",
       " '여': 275,\n",
       " '모든': 276,\n",
       " '쓰': 277,\n",
       " '아직': 278,\n",
       " '5': 279,\n",
       " '추천': 280,\n",
       " '처럼': 281,\n",
       " '눈': 282,\n",
       " '아닌': 283,\n",
       " '자체': 284,\n",
       " '4': 285,\n",
       " '울': 286,\n",
       " '대박': 287,\n",
       " '몰입': 288,\n",
       " '몇': 289,\n",
       " '실망': 290,\n",
       " '스럽': 291,\n",
       " '는다': 292,\n",
       " '대한': 293,\n",
       " '죠': 294,\n",
       " '란': 295,\n",
       " '그런': 296,\n",
       " '솔직히': 297,\n",
       " 'ㅎ': 298,\n",
       " '캐릭터': 299,\n",
       " '아주': 300,\n",
       " '모두': 301,\n",
       " '-': 302,\n",
       " '가족': 303,\n",
       " '여운': 304,\n",
       " '건지': 305,\n",
       " '전혀': 306,\n",
       " '연기력': 307,\n",
       " '나라': 308,\n",
       " '후': 309,\n",
       " '다면': 310,\n",
       " '될': 311,\n",
       " '뭔가': 312,\n",
       " '그래도': 313,\n",
       " ';': 314,\n",
       " '시리즈': 315,\n",
       " '근데': 316,\n",
       " '작': 317,\n",
       " '표현': 318,\n",
       " '모습': 319,\n",
       " '공감': 320,\n",
       " '계속': 321,\n",
       " '먹': 322,\n",
       " '\"\"': 323,\n",
       " '제목': 324,\n",
       " '7': 325,\n",
       " '이랑': 326,\n",
       " '극장': 327,\n",
       " '치': 328,\n",
       " '비': 329,\n",
       " '이걸': 330,\n",
       " '진': 331,\n",
       " '바': 332,\n",
       " '0': 333,\n",
       " 'OO': 334,\n",
       " '그렇': 335,\n",
       " '대사': 336,\n",
       " '부분': 337,\n",
       " '개봉': 338,\n",
       " '대단': 339,\n",
       " '어디': 340,\n",
       " '된다': 341,\n",
       " '작가': 342,\n",
       " '기분': 343,\n",
       " '아쉽': 344,\n",
       " '제': 345,\n",
       " '진심': 346,\n",
       " '타임': 347,\n",
       " '/': 348,\n",
       " '놓': 349,\n",
       " '웃기': 350,\n",
       " '보이': 351,\n",
       " '해도': 352,\n",
       " '이제': 353,\n",
       " '물': 354,\n",
       " '봐야': 355,\n",
       " '막장': 356,\n",
       " '삶': 357,\n",
       " '친구': 358,\n",
       " '잔잔': 359,\n",
       " '씬': 360,\n",
       " '조금': 361,\n",
       " '딱': 362,\n",
       " '억지': 363,\n",
       " '영상': 364,\n",
       " '찾': 365,\n",
       " '요즘': 366,\n",
       " '같이': 367,\n",
       " '\"': 368,\n",
       " '중간': 369,\n",
       " '구': 370,\n",
       " '스릴러': 371,\n",
       " '라도': 372,\n",
       " '....': 373,\n",
       " '가지': 374,\n",
       " '8': 375,\n",
       " '믿': 376,\n",
       " '싫': 377,\n",
       " '아까운': 378,\n",
       " '나왔': 379,\n",
       " '점수': 380,\n",
       " '긴장감': 381,\n",
       " '부족': 382,\n",
       " '개인': 383,\n",
       " '제대로': 384,\n",
       " '노래': 385,\n",
       " '이유': 386,\n",
       " '만큼': 387,\n",
       " '라면': 388,\n",
       " '시작': 389,\n",
       " '구나': 390,\n",
       " '잇': 391,\n",
       " '특히': 392,\n",
       " '한테': 393,\n",
       " '날': 394,\n",
       " '아름다운': 395,\n",
       " '려고': 396,\n",
       " '제일': 397,\n",
       " '시대': 398,\n",
       " 'ㅜㅜ': 399,\n",
       " '어떻게': 400,\n",
       " '엔딩': 401,\n",
       " '당시': 402,\n",
       " '봐': 403,\n",
       " '하지만': 404,\n",
       " '나름': 405,\n",
       " '무섭': 406,\n",
       " '명': 407,\n",
       " '나온': 408,\n",
       " '해요': 409,\n",
       " '이것': 410,\n",
       " '사': 411,\n",
       " '오랜만': 412,\n",
       " '9': 413,\n",
       " '니까': 414,\n",
       " '팬': 415,\n",
       " '차라리': 416,\n",
       " '절대': 417,\n",
       " '세상': 418,\n",
       " '세': 419,\n",
       " '던데': 420,\n",
       " '의미': 421,\n",
       " '못하': 422,\n",
       " '따뜻': 423,\n",
       " '봄': 424,\n",
       " '욕': 425,\n",
       " '강추': 426,\n",
       " '훌륭': 427,\n",
       " '너무나': 428,\n",
       " 'ㅡ': 429,\n",
       " '감': 430,\n",
       " '됨': 431,\n",
       " '느끼': 432,\n",
       " '해야': 433,\n",
       " '빼': 434,\n",
       " '드': 435,\n",
       " '도대체': 436,\n",
       " '어야': 437,\n",
       " '답답': 438,\n",
       " '마다': 439,\n",
       " '준다': 440,\n",
       " '놈': 441,\n",
       " '글': 442,\n",
       " '전쟁': 443,\n",
       " '수작': 444,\n",
       " '설정': 445,\n",
       " '무엇': 446,\n",
       " '흥미': 447,\n",
       " '그저': 448,\n",
       " '만화': 449,\n",
       " '감정': 450,\n",
       " '미국': 451,\n",
       " '행복': 452,\n",
       " '신선': 453,\n",
       " '뻔': 454,\n",
       " '군': 455,\n",
       " '허접': 456,\n",
       " '형': 457,\n",
       " '앞': 458,\n",
       " '어도': 459,\n",
       " '관객': 460,\n",
       " '배경': 461,\n",
       " '시절': 462,\n",
       " '6': 463,\n",
       " '초반': 464,\n",
       " '사실': 465,\n",
       " '웃음': 466,\n",
       " 'OOO': 467,\n",
       " '엄청': 468,\n",
       " '답': 469,\n",
       " '더라': 470,\n",
       " '추억': 471,\n",
       " '라니': 472,\n",
       " '질': 473,\n",
       " '자신': 474,\n",
       " '캐스팅': 475,\n",
       " '류': 476,\n",
       " '첨': 477,\n",
       " '멋있': 478,\n",
       " '어색': 479,\n",
       " '시나리오': 480,\n",
       " '슬프': 481,\n",
       " '머': 482,\n",
       " '소름': 483,\n",
       " '밖에': 484,\n",
       " '정신': 485,\n",
       " '분위기': 486,\n",
       " '멋진': 487,\n",
       " '힘들': 488,\n",
       " '오늘': 489,\n",
       " '졸작': 490,\n",
       " '어이없': 491,\n",
       " '잡': 492,\n",
       " '봐서': 493,\n",
       " '킬링': 494,\n",
       " '위해': 495,\n",
       " '문제': 496,\n",
       " '구성': 497,\n",
       " '엄마': 498,\n",
       " '함께': 499,\n",
       " '이딴': 500,\n",
       " '잊': 501,\n",
       " '등': 502,\n",
       " '집': 503,\n",
       " '유쾌': 504,\n",
       " '뻔한': 505,\n",
       " '스러운': 506,\n",
       " '결국': 507,\n",
       " '낫': 508,\n",
       " '뭘': 509,\n",
       " '어떤': 510,\n",
       " '한데': 511,\n",
       " '나요': 512,\n",
       " '소리': 513,\n",
       " '간': 514,\n",
       " '역사': 515,\n",
       " '20': 516,\n",
       " '뭔': 517,\n",
       " '제발': 518,\n",
       " '포스터': 519,\n",
       " '아무리': 520,\n",
       " '코믹': 521,\n",
       " '!!!': 522,\n",
       " '완벽': 523,\n",
       " '~~~': 524,\n",
       " '애니메이션': 525,\n",
       " '맘': 526,\n",
       " '얼마나': 527,\n",
       " '난다': 528,\n",
       " '러': 529,\n",
       " '주연': 530,\n",
       " '원': 531,\n",
       " '♥': 532,\n",
       " '버리': 533,\n",
       " '어릴': 534,\n",
       " '후회': 535,\n",
       " '진부': 536,\n",
       " '나올': 537,\n",
       " '됐': 538,\n",
       " '장난': 539,\n",
       " '책': 540,\n",
       " '보단': 541,\n",
       " '큰': 542,\n",
       " '더니': 543,\n",
       " '영화관': 544,\n",
       " '개연': 545,\n",
       " '출연': 546,\n",
       " '둘': 547,\n",
       " '보고': 548,\n",
       " '극': 549,\n",
       " 'ㅅ': 550,\n",
       " '줬': 551,\n",
       " '밖': 552,\n",
       " '충격': 553,\n",
       " '여기': 554,\n",
       " '아름답': 555,\n",
       " '엇': 556,\n",
       " '잔인': 557,\n",
       " '얘기': 558,\n",
       " '평가': 559,\n",
       " '꺼': 560,\n",
       " '예술': 561,\n",
       " '매우': 562,\n",
       " '봐라': 563,\n",
       " '갈수록': 564,\n",
       " '든': 565,\n",
       " '이리': 566,\n",
       " '자기': 567,\n",
       " '위한': 568,\n",
       " '읽': 569,\n",
       " '이후': 570,\n",
       " '반': 571,\n",
       " '얼굴': 572,\n",
       " '꽤': 573,\n",
       " '낭비': 574,\n",
       " '티비': 575,\n",
       " '이쁘': 576,\n",
       " '옛날': 577,\n",
       " '으나': 578,\n",
       " '별점': 579,\n",
       " '깊': 580,\n",
       " '불쌍': 581,\n",
       " '불': 582,\n",
       " '못한': 583,\n",
       " '겟': 584,\n",
       " '시청': 585,\n",
       " '순수': 586,\n",
       " '라서': 587,\n",
       " '언제': 588,\n",
       " '건가': 589,\n",
       " '비디오': 590,\n",
       " '머리': 591,\n",
       " '애니': 592,\n",
       " '장르': 593,\n",
       " '텐데': 594,\n",
       " '+': 595,\n",
       " '생각나': 596,\n",
       " '배': 597,\n",
       " '미': 598,\n",
       " ':': 599,\n",
       " '그래서': 600,\n",
       " '다운': 601,\n",
       " '주제': 602,\n",
       " '다큐': 603,\n",
       " '다음': 604,\n",
       " '궁금': 605,\n",
       " '아님': 606,\n",
       " '시키': 607,\n",
       " '그렇게': 608,\n",
       " '누구': 609,\n",
       " '예전': 610,\n",
       " '크': 611,\n",
       " '그만': 612,\n",
       " '동안': 613,\n",
       " '뒤': 614,\n",
       " '??': 615,\n",
       " '인상': 616,\n",
       " '상황': 617,\n",
       " '이름': 618,\n",
       " '감사': 619,\n",
       " '미친': 620,\n",
       " '스릴': 621,\n",
       " '아무': 622,\n",
       " '시즌': 623,\n",
       " '오래': 624,\n",
       " '너': 625,\n",
       " 'B': 626,\n",
       " '집중': 627,\n",
       " '힘': 628,\n",
       " '그러': 629,\n",
       " '어느': 630,\n",
       " '본다': 631,\n",
       " '로맨스': 632,\n",
       " '진정': 633,\n",
       " '약간': 634,\n",
       " '나와서': 635,\n",
       " '식': 636,\n",
       " '마세요': 637,\n",
       " '까': 638,\n",
       " '방송': 639,\n",
       " '그나마': 640,\n",
       " '짜리': 641,\n",
       " '평': 642,\n",
       " '꿈': 643,\n",
       " '소설': 644,\n",
       " '여주인공': 645,\n",
       " '걸작': 646,\n",
       " '에요': 647,\n",
       " '몰': 648,\n",
       " '존나': 649,\n",
       " '그대로': 650,\n",
       " '죽이': 651,\n",
       " '인물': 652,\n",
       " '났': 653,\n",
       " '그것': 654,\n",
       " '회': 655,\n",
       " '떨어지': 656,\n",
       " '케': 657,\n",
       " '왔': 658,\n",
       " '만점': 659,\n",
       " '실화': 660,\n",
       " '대체': 661,\n",
       " '해라': 662,\n",
       " '훨씬': 663,\n",
       " '짓': 664,\n",
       " '~!': 665,\n",
       " '무': 666,\n",
       " '발연기': 667,\n",
       " '사회': 668,\n",
       " '전체': 669,\n",
       " '구만': 670,\n",
       " 'ㅜ': 671,\n",
       " '비슷': 672,\n",
       " '누가': 673,\n",
       " '30': 674,\n",
       " '막': 675,\n",
       " '끝나': 676,\n",
       " '햇': 677,\n",
       " '엉성': 678,\n",
       " 'CG': 679,\n",
       " '귀엽': 680,\n",
       " '여주': 681,\n",
       " '단': 682,\n",
       " '영상미': 683,\n",
       " '중국': 684,\n",
       " '초딩': 685,\n",
       " '비교': 686,\n",
       " '감성': 687,\n",
       " '네이버': 688,\n",
       " '세계': 689,\n",
       " '꿀': 690,\n",
       " '여배우': 691,\n",
       " '는가': 692,\n",
       " '더럽': 693,\n",
       " '망': 694,\n",
       " 'ㅎㅎㅎ': 695,\n",
       " '순간': 696,\n",
       " '느껴': 697,\n",
       " '려는': 698,\n",
       " ';;;': 699,\n",
       " '나이': 700,\n",
       " '상': 701,\n",
       " '대해': 702,\n",
       " '첫': 703,\n",
       " '어렸': 704,\n",
       " '생': 705,\n",
       " '쯤': 706,\n",
       " '판': 707,\n",
       " '입': 708,\n",
       " '돋': 709,\n",
       " '갔': 710,\n",
       " '가능': 711,\n",
       " '어설픈': 712,\n",
       " '셨': 713,\n",
       " '학교': 714,\n",
       " '100': 715,\n",
       " '성룡': 716,\n",
       " '타': 717,\n",
       " '혼자': 718,\n",
       " '아들': 719,\n",
       " '느낄': 720,\n",
       " '멋지': 721,\n",
       " '아야': 722,\n",
       " '졸': 723,\n",
       " '.....': 724,\n",
       " '어린': 725,\n",
       " '바로': 726,\n",
       " '나가': 727,\n",
       " '교훈': 728,\n",
       " '잘못': 729,\n",
       " '굳': 730,\n",
       " '한마디': 731,\n",
       " '맛': 732,\n",
       " '길래': 733,\n",
       " '존': 734,\n",
       " '판타지': 735,\n",
       " '딸': 736,\n",
       " '당신': 737,\n",
       " '화려': 738,\n",
       " '끌': 739,\n",
       " '티': 740,\n",
       " '삼류': 741,\n",
       " '아까움': 742,\n",
       " '잠': 743,\n",
       " '땜': 744,\n",
       " '든다': 745,\n",
       " '차': 746,\n",
       " '달': 747,\n",
       " '똥': 748,\n",
       " '맨': 749,\n",
       " '빨리': 750,\n",
       " '목소리': 751,\n",
       " '영': 752,\n",
       " '당': 753,\n",
       " '거의': 754,\n",
       " '나온다': 755,\n",
       " '듣': 756,\n",
       " '전부': 757,\n",
       " '봤었': 758,\n",
       " 'ㅉㅉ': 759,\n",
       " '독특': 760,\n",
       " '다르': 761,\n",
       " '가치': 762,\n",
       " '건데': 763,\n",
       " '초': 764,\n",
       " '어른': 765,\n",
       " '위': 766,\n",
       " '률': 767,\n",
       " '상당히': 768,\n",
       " '씩': 769,\n",
       " '90': 770,\n",
       " '다만': 771,\n",
       " '질질': 772,\n",
       " '넣': 773,\n",
       " '아버지': 774,\n",
       " '평론가': 775,\n",
       " '갑자기': 776,\n",
       " '줄거리': 777,\n",
       " '한번': 778,\n",
       " '이번': 779,\n",
       " '스타일': 780,\n",
       " '이러': 781,\n",
       " '그러나': 782,\n",
       " '여러': 783,\n",
       " '군요': 784,\n",
       " 'ㅂ': 785,\n",
       " '의도': 786,\n",
       " '저런': 787,\n",
       " '존재': 788,\n",
       " '밑': 789,\n",
       " '허무': 790,\n",
       " '%': 791,\n",
       " '부': 792,\n",
       " '대로': 793,\n",
       " '에선': 794,\n",
       " '째': 795,\n",
       " '각본': 796,\n",
       " '성우': 797,\n",
       " '예상': 798,\n",
       " '지루함': 799,\n",
       " '으면서': 800,\n",
       " '버린': 801,\n",
       " '그녀': 802,\n",
       " '너무너무': 803,\n",
       " '화면': 804,\n",
       " 'ㄱ': 805,\n",
       " '떠나': 806,\n",
       " '예쁘': 807,\n",
       " '비해': 808,\n",
       " '자연': 809,\n",
       " '담': 810,\n",
       " '평범': 811,\n",
       " '굉장히': 812,\n",
       " '그런지': 813,\n",
       " '뻔하': 814,\n",
       " '만나': 815,\n",
       " '슬픈': 816,\n",
       " '돼': 817,\n",
       " '못했': 818,\n",
       " '복수': 819,\n",
       " '관람': 820,\n",
       " '일단': 821,\n",
       " '줌': 822,\n",
       " '스': 823,\n",
       " '단순': 824,\n",
       " '새로운': 825,\n",
       " '댓글': 826,\n",
       " '중요': 827,\n",
       " '낸': 828,\n",
       " '피': 829,\n",
       " '앗': 830,\n",
       " '극장판': 831,\n",
       " '갖': 832,\n",
       " '제작': 833,\n",
       " '버렸': 834,\n",
       " '만족': 835,\n",
       " '쉽': 836,\n",
       " '선택': 837,\n",
       " '진행': 838,\n",
       " '아빠': 839,\n",
       " '쓴': 840,\n",
       " 'TV': 841,\n",
       " '요소': 842,\n",
       " '거나': 843,\n",
       " '한편': 844,\n",
       " '불편': 845,\n",
       " '항상': 846,\n",
       " '거기': 847,\n",
       " '연출력': 848,\n",
       " '그때': 849,\n",
       " '잃': 850,\n",
       " '롭': 851,\n",
       " '한다는': 852,\n",
       " '에로': 853,\n",
       " '산': 854,\n",
       " '탄탄': 855,\n",
       " '발': 856,\n",
       " '예요': 857,\n",
       " '나옴': 858,\n",
       " '한심': 859,\n",
       " '흥행': 860,\n",
       " '물론': 861,\n",
       " '려': 862,\n",
       " '지나': 863,\n",
       " '따라': 864,\n",
       " '전형': 865,\n",
       " '점점': 866,\n",
       " '이하': 867,\n",
       " '관계': 868,\n",
       " '역대': 869,\n",
       " '편집': 870,\n",
       " '조': 871,\n",
       " '아까워': 872,\n",
       " '짧': 873,\n",
       " '법': 874,\n",
       " '던가': 875,\n",
       " '총': 876,\n",
       " '따': 877,\n",
       " '충분히': 878,\n",
       " '안타깝': 879,\n",
       " '에겐': 880,\n",
       " '아닌가': 881,\n",
       " '화이팅': 882,\n",
       " '식상': 883,\n",
       " 'tv': 884,\n",
       " '80': 885,\n",
       " '몰랐': 886,\n",
       " '김': 887,\n",
       " '자꾸': 888,\n",
       " '훈훈': 889,\n",
       " '미안': 890,\n",
       " '-_-': 891,\n",
       " '도록': 892,\n",
       " '게임': 893,\n",
       " '멜': 894,\n",
       " '장': 895,\n",
       " '원래': 896,\n",
       " '곳': 897,\n",
       " '그게': 898,\n",
       " '자극': 899,\n",
       " '몸': 900,\n",
       " '삼': 901,\n",
       " '손': 902,\n",
       " '~!!': 903,\n",
       " '구요': 904,\n",
       " '나쁜': 905,\n",
       " '어쩔': 906,\n",
       " '사건': 907,\n",
       " '설명': 908,\n",
       " '간다': 909,\n",
       " '팔': 910,\n",
       " '똑같': 911,\n",
       " '뭔지': 912,\n",
       " '풀': 913,\n",
       " '잖아': 914,\n",
       " '어울리': 915,\n",
       " '짜': 916,\n",
       " '귀신': 917,\n",
       " '짐': 918,\n",
       " '과거': 919,\n",
       " '빙': 920,\n",
       " '노력': 921,\n",
       " '그래픽': 922,\n",
       " '황당': 923,\n",
       " '도저히': 924,\n",
       " '조차': 925,\n",
       " '닿': 926,\n",
       " '됬': 927,\n",
       " '아프': 928,\n",
       " '중반': 929,\n",
       " '빠': 930,\n",
       " '개그': 931,\n",
       " '죽음': 932,\n",
       " '듬': 933,\n",
       " '프랑스': 934,\n",
       " '코메디': 935,\n",
       " '미치': 936,\n",
       " '홍콩': 937,\n",
       " '취향': 938,\n",
       " '빠져': 939,\n",
       " '속편': 940,\n",
       " '했었': 941,\n",
       " '역': 942,\n",
       " '무비': 943,\n",
       " '무조건': 944,\n",
       " '짱짱': 945,\n",
       " '소중': 946,\n",
       " '헐': 947,\n",
       " '이란': 948,\n",
       " '프로': 949,\n",
       " '멋': 950,\n",
       " '참신': 951,\n",
       " 'good': 952,\n",
       " '쳐': 953,\n",
       " '병맛': 954,\n",
       " '나쁘': 955,\n",
       " '좋아하': 956,\n",
       " '특유': 957,\n",
       " '비추': 958,\n",
       " '아쉬운': 959,\n",
       " '괜히': 960,\n",
       " '빠지': 961,\n",
       " '척': 962,\n",
       " '더욱': 963,\n",
       " '넘치': 964,\n",
       " '진지': 965,\n",
       " '리': 966,\n",
       " '또한': 967,\n",
       " '유명': 968,\n",
       " '상상': 969,\n",
       " '숨': 970,\n",
       " '상영': 971,\n",
       " '결혼': 972,\n",
       " '전설': 973,\n",
       " 'ost': 974,\n",
       " '심리': 975,\n",
       " '무서운': 976,\n",
       " '엄청난': 977,\n",
       " '인듯': 978,\n",
       " '희망': 979,\n",
       " '오히려': 980,\n",
       " '예고편': 981,\n",
       " '별루': 982,\n",
       " '후반부': 983,\n",
       " '아저씨': 984,\n",
       " '틀': 985,\n",
       " '더빙': 986,\n",
       " '으니': 987,\n",
       " '고자': 988,\n",
       " '왕': 989,\n",
       " '심하': 990,\n",
       " '바보': 991,\n",
       " '연기자': 992,\n",
       " 'ㄴ': 993,\n",
       " '쩔': 994,\n",
       " '촬영': 995,\n",
       " '그리': 996,\n",
       " '소녀': 997,\n",
       " '느꼈': 998,\n",
       " '끝내': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cabd9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "18d9a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec1ed190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 4, 27, 2], [1, 27, 2, 2]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"이 영화 정말 재미있어요\", \"정말 재미없는 영화였어요\"]\n",
    "get_encoded_sentences(sentences, word_to_index) # [[1, 2, 4, 27, 2], [1, 27, 2, 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9a0e7980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<UNK> 영화 정말 <UNK>', '정말 <UNK> <UNK>']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences = [[1, 2, 4, 27, 2], [1, 27, 2, 2]]\n",
    "get_decoded_sentences(encoded_sentences, index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f6ba1",
   "metadata": {},
   "source": [
    "## 3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "* 데이터셋 내 문장 길이 분포\n",
    "* 적절한 최대 문장 길이 지정\n",
    "* keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f237e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  18.3542491699668\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  15.347552229578971\n",
      "pad_sequences maxlen :  55\n",
      "전체 문장의 0.9506380255210208%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2.4 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d641da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149995, 55) (49997, 55)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(np.array(X_train,dtype=object),\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(np.array(X_test,dtype=object),\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9e13b",
   "metadata": {},
   "source": [
    "## 4) 모델 구성 및 validation set 구성\n",
    "## 5) 모델 훈련 개시\n",
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d997c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99995, 55)\n",
      "(99995,)\n"
     ]
    }
   ],
   "source": [
    "X_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c44125",
   "metadata": {},
   "source": [
    "1. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b6be6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, None, 16)          800000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 800,809\n",
      "Trainable params: 800,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50000    # 어휘 사전의 크기입니다\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,),mask_zero=True))\n",
    "model.add(tf.keras.layers.LSTM(8,recurrent_dropout=0.25))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "feb6fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "196/196 [==============================] - 46s 224ms/step - loss: 0.5631 - accuracy: 0.7556 - val_loss: 0.4189 - val_accuracy: 0.8325\n",
      "Epoch 2/5\n",
      "196/196 [==============================] - 44s 222ms/step - loss: 0.3887 - accuracy: 0.8536 - val_loss: 0.3611 - val_accuracy: 0.8481\n",
      "Epoch 3/5\n",
      "196/196 [==============================] - 43s 221ms/step - loss: 0.3319 - accuracy: 0.8787 - val_loss: 0.3529 - val_accuracy: 0.8499\n",
      "Epoch 4/5\n",
      "196/196 [==============================] - 44s 223ms/step - loss: 0.2991 - accuracy: 0.8930 - val_loss: 0.3571 - val_accuracy: 0.8496\n",
      "Epoch 5/5\n",
      "196/196 [==============================] - 43s 221ms/step - loss: 0.2756 - accuracy: 0.9032 - val_loss: 0.3712 - val_accuracy: 0.8466\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs= 5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ee296870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.3836 - accuracy: 0.8418\n",
      "[0.38361769914627075, 0.8417505025863647]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "02894ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 서브플롯을 생성합니다\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# 첫 번째 서브플롯: Training and Validation Loss\n",
    "ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# 두 번째 서브플롯: Training and Validation Accuracy\n",
    "ax2.plot(epochs, acc, 'bo', label='Training acc')\n",
    "ax2.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "ax2.set_title('Training and validation accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# 서브플롯 간의 간격을 조정합니다\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그래프를 출력합니다\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe851a",
   "metadata": {},
   "source": [
    "2. 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000    # 어휘 사전의 크기입니다\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06266c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs= 5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b86710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 서브플롯을 생성합니다\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# 첫 번째 서브플롯: Training and Validation Loss\n",
    "ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# 두 번째 서브플롯: Training and Validation Accuracy\n",
    "ax2.plot(epochs, acc, 'bo', label='Training acc')\n",
    "ax2.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "ax2.set_title('Training and validation accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# 서브플롯 간의 간격을 조정합니다\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그래프를 출력합니다\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0dca6",
   "metadata": {},
   "source": [
    "2. LSTM Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000    # 어휘 사전의 크기입니다\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,),mask_zero=True))\n",
    "model.add(tf.keras.layers.LSTM(8,recurrent_dropout=0.25,return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(8,recurrent_dropout=0.25))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs= 5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bc431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 서브플롯을 생성합니다\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# 첫 번째 서브플롯: Training and Validation Loss\n",
    "ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# 두 번째 서브플롯: Training and Validation Accuracy\n",
    "ax2.plot(epochs, acc, 'bo', label='Training acc')\n",
    "ax2.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "ax2.set_title('Training and validation accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "# 서브플롯 간의 간격을 조정합니다\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그래프를 출력합니다\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda58bc",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4e68e37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aa8894c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec2.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-3, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 3개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(3,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c28ce1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15956989,  0.06709275,  0.1838534 , -0.1328995 ,  0.17581128,\n",
       "       -0.10071933, -0.03515879, -0.04138393, -0.07211126, -0.06571133,\n",
       "        0.19327241, -0.06522657, -0.11421046,  0.1468657 ,  0.12326947,\n",
       "        0.18790196], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['강추']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "100beb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('우민', 0.8803641200065613),\n",
       " ('동', 0.8456517457962036),\n",
       " ('갖춘다', 0.8405343294143677),\n",
       " ('그레이', 0.8384608626365662),\n",
       " ('아홉수', 0.8372870087623596),\n",
       " ('위치', 0.8360053896903992),\n",
       " ('저작권료', 0.8312565684318542),\n",
       " ('ㅜ내용이점점뻔해지는듯', 0.8265794515609741),\n",
       " ('Thing', 0.826439619064331),\n",
       " ('다카코', 0.8262174725532532)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"긴장\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeefed5",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선\n",
    "* 한국어 Word2Vec은 /data 폴더 안에 있는 word2vec_ko.model을 활용하세요.\n",
    "* 한국어 Word2Vec을 활용할 때는 load_word2vec_format() 형태가 아닌 load() 형태로 모델을 불러와주세요. 또한 모델을 활용할 때에는 아래 예시와 같이 .wv를 붙여서 활용합니다. 좀더 자세한 활용법에 대해선 다음 링크들을 참조해주세요. 참고 링크1, 참고 링크2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c014c4",
   "metadata": {},
   "source": [
    "```\n",
    "# 예시 코드\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "vector = word_vectors.wv[‘끝’]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15c71714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.8550365 , -2.5083623 ,  0.63134253,  1.2381471 ,  1.2327392 ,\n",
       "       -0.72185796,  1.8402325 ,  0.97800475, -1.1051553 ,  2.0433369 ,\n",
       "        0.69271207, -0.19798934, -1.86177   , -0.36222002,  0.3972282 ,\n",
       "       -0.21830237,  0.85162693, -0.31651935,  1.6791793 , -2.6823583 ,\n",
       "       -1.8238554 ,  1.9019375 ,  0.25607604, -0.57341754,  1.4750755 ,\n",
       "        0.86539614, -2.1937923 ,  1.331522  ,  1.4148315 ,  0.05106315,\n",
       "       -1.0021658 ,  0.3949725 , -1.4810442 ,  2.4344177 , -2.0451741 ,\n",
       "        4.163476  , -1.9220031 , -0.6334712 , -1.1372192 ,  0.19194362,\n",
       "       -0.5145045 , -0.1731505 ,  0.77141196,  1.1994339 ,  0.5596351 ,\n",
       "        1.6327816 ,  1.6391085 ,  2.224425  ,  1.0831126 ,  0.10987365,\n",
       "        0.67111415, -1.64053   ,  0.20209534, -1.7971501 , -0.64727396,\n",
       "       -1.1733613 ,  1.2080375 , -1.1791579 ,  0.24168837,  1.9009135 ,\n",
       "        2.6488237 , -2.7944257 , -0.8682773 , -2.8367517 , -0.14049563,\n",
       "       -0.4478784 , -3.1858766 ,  0.61623126, -1.3198127 ,  0.80738777,\n",
       "       -0.2375696 , -1.2739844 , -0.18748645,  0.96437085, -2.0523639 ,\n",
       "       -2.438767  , -2.7684495 , -1.4699064 ,  0.43434626, -1.735144  ,\n",
       "        0.35697916, -0.31166923, -0.09702326,  0.19784144,  2.1842256 ,\n",
       "       -1.3189126 ,  1.6997315 ,  1.9437138 ,  0.48777846, -1.3102893 ,\n",
       "       -4.008401  , -1.7939562 ,  0.18164791, -3.4320853 ,  0.11291533,\n",
       "        0.8925207 , -1.4193492 , -0.9740778 ,  1.031152  , -2.274115  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec_ko.model'\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "vector = word_vectors.wv['안녕']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80e2f08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('긴장감', 0.7897169589996338),\n",
       " ('갈등', 0.745145857334137),\n",
       " ('혼란', 0.7212201952934265),\n",
       " ('불안', 0.709709882736206),\n",
       " ('반목', 0.700858473777771),\n",
       " ('불안감', 0.6817017793655396),\n",
       " ('불신', 0.6665791273117065),\n",
       " ('알력', 0.6642228364944458),\n",
       " ('마찰', 0.6541054844856262),\n",
       " ('흥분', 0.6478731632232666)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word_vectors.wv.similar_by_word(\"긴장\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f299f54",
   "metadata": {},
   "source": [
    "> 네이버영화리뷰사전보다는 정확성이 훨씬 좋은게 느껴진다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "372bb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000    \n",
    "word_vector_dim = 100  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 word_vectors 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(3,vocab_size):\n",
    "    if index_to_word[i] in word_vectors.wv:\n",
    "        embedding_matrix[i] = word_vectors.wv[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ebcb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 55, 100)           5000000   \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 54, 16)            3216      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 27, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 26, 16)            528       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 13, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 12, 16)            528       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 6, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5, 16)             528       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1, 16)             528       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 5,005,473\n",
      "Trainable params: 5,005,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 50000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 2, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Conv1D(16, 2, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Conv1D(16, 2, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Conv1D(16, 2, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(2))\n",
    "model.add(tf.keras.layers.Conv1D(16, 2, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35819628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "196/196 [==============================] - 3s 11ms/step - loss: 0.6327 - accuracy: 0.6230 - val_loss: 0.5307 - val_accuracy: 0.7378\n",
      "Epoch 2/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.4887 - accuracy: 0.7678 - val_loss: 0.4548 - val_accuracy: 0.7907\n",
      "Epoch 3/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.4204 - accuracy: 0.8111 - val_loss: 0.4107 - val_accuracy: 0.8144\n",
      "Epoch 4/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.3748 - accuracy: 0.8368 - val_loss: 0.3861 - val_accuracy: 0.8280\n",
      "Epoch 5/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.3408 - accuracy: 0.8555 - val_loss: 0.3747 - val_accuracy: 0.8350\n",
      "Epoch 6/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.3135 - accuracy: 0.8701 - val_loss: 0.3773 - val_accuracy: 0.8342\n",
      "Epoch 7/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.2904 - accuracy: 0.8820 - val_loss: 0.3676 - val_accuracy: 0.8404\n",
      "Epoch 8/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.2694 - accuracy: 0.8925 - val_loss: 0.3685 - val_accuracy: 0.8429\n",
      "Epoch 9/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.2509 - accuracy: 0.9024 - val_loss: 0.3699 - val_accuracy: 0.8435\n",
      "Epoch 10/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.2320 - accuracy: 0.9109 - val_loss: 0.3801 - val_accuracy: 0.8422\n",
      "Epoch 11/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.2164 - accuracy: 0.9186 - val_loss: 0.3948 - val_accuracy: 0.8426\n",
      "Epoch 12/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.2014 - accuracy: 0.9256 - val_loss: 0.4076 - val_accuracy: 0.8408\n",
      "Epoch 13/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.1879 - accuracy: 0.9318 - val_loss: 0.4177 - val_accuracy: 0.8389\n",
      "Epoch 14/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.1752 - accuracy: 0.9376 - val_loss: 0.4408 - val_accuracy: 0.8383\n",
      "Epoch 15/15\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.1651 - accuracy: 0.9417 - val_loss: 0.4635 - val_accuracy: 0.8363\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=15  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1b6fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.4738 - accuracy: 0.8332\n",
      "[0.47377830743789673, 0.8332099914550781]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evalbuate(X_test,  y_test, verbose=1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5e626",
   "metadata": {},
   "source": [
    "# 회고\n",
    "* 가장 힘든 프로젝트였다. 변수를 선택해야 하는 경우가 가장 많았던 듯 합니다.\n",
    "* 트랜스포머를 확실히 이해했으면 사용해 봤을 듯 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
