{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776fc1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a087834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f302be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9228d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e391712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef65556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트(sentences)를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "414ac0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce4dbc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7892f",
   "metadata": {},
   "source": [
    "### 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. 문장길이가 같지 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "082506ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2911302848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4954b",
   "metadata": {},
   "source": [
    "### 문장길이 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c25905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2999990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.01129692 -0.04312481 -0.03132869  0.04728994]\n",
      "  [-0.01240462  0.00412757  0.01040374  0.00987814]\n",
      "  [-0.02878586  0.01323494 -0.01860707 -0.04784873]\n",
      "  [ 0.0207083  -0.04769421 -0.00465102 -0.0107705 ]\n",
      "  [ 0.0092868  -0.03070017 -0.00504779  0.01731998]]\n",
      "\n",
      " [[-0.01129692 -0.04312481 -0.03132869  0.04728994]\n",
      "  [-0.01240462  0.00412757  0.01040374  0.00987814]\n",
      "  [-0.04729184  0.04299891 -0.01608501  0.009115  ]\n",
      "  [ 0.01208042 -0.01601125  0.02040453 -0.02416346]\n",
      "  [ 0.0092868  -0.03070017 -0.00504779  0.01731998]]\n",
      "\n",
      " [[-0.01129692 -0.04312481 -0.03132869  0.04728994]\n",
      "  [ 0.03795763 -0.00982454 -0.00551146  0.01504505]\n",
      "  [-0.01240462  0.00412757  0.01040374  0.00987814]\n",
      "  [-0.02878586  0.01323494 -0.01860707 -0.04784873]\n",
      "  [-0.03665262 -0.03085501  0.01061238  0.04961452]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "# 이부분이 추가됨\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "# 여기까지\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bc4f2",
   "metadata": {},
   "source": [
    "### RNN 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43a12351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e47e55d",
   "metadata": {},
   "source": [
    "### 1D CNN 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91499500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62ae8c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling만 적용한 경우\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D()) # 이거 하나만 적용\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a79e7",
   "metadata": {},
   "source": [
    "### 본격적인 감성분석\n",
    "imdb.load_data() 호출 시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면, 그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94156489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "# 긍정은 1, 부정은 0\n",
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57a4d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eba119b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ee95599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cfdc91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c11b78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba44a0",
   "metadata": {},
   "source": [
    "### 문장길이 통일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cc7467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5069978",
   "metadata": {},
   "source": [
    "유의해야 하는 것은 padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느 쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "304bac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580) (25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # post | 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # post | 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd475b",
   "metadata": {},
   "source": [
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 됩니다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적입니다. 따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832fcc6d",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f983d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df5fb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e648f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 46ms/step - loss: 0.6931 - accuracy: 0.5059 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6928 - accuracy: 0.5137 - val_loss: 0.6932 - val_accuracy: 0.5015\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6924 - accuracy: 0.5207 - val_loss: 0.6927 - val_accuracy: 0.5055\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6918 - accuracy: 0.5097 - val_loss: 0.6927 - val_accuracy: 0.5033\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6898 - accuracy: 0.5090 - val_loss: 0.6923 - val_accuracy: 0.5028\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6842 - accuracy: 0.5211 - val_loss: 0.6888 - val_accuracy: 0.5073\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6759 - accuracy: 0.5317 - val_loss: 0.6886 - val_accuracy: 0.5254\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6762 - accuracy: 0.5327 - val_loss: 0.6880 - val_accuracy: 0.5084\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6708 - accuracy: 0.5329 - val_loss: 0.6885 - val_accuracy: 0.5087\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6669 - accuracy: 0.5360 - val_loss: 0.6927 - val_accuracy: 0.5098\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6630 - accuracy: 0.5371 - val_loss: 0.6910 - val_accuracy: 0.5115\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6597 - accuracy: 0.5375 - val_loss: 0.6916 - val_accuracy: 0.5134\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6572 - accuracy: 0.5379 - val_loss: 0.6937 - val_accuracy: 0.5133\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6554 - accuracy: 0.5381 - val_loss: 0.6930 - val_accuracy: 0.5138\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6543 - accuracy: 0.5346 - val_loss: 0.6898 - val_accuracy: 0.5158\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6580 - accuracy: 0.5301 - val_loss: 0.6969 - val_accuracy: 0.5119\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6543 - accuracy: 0.5380 - val_loss: 0.6923 - val_accuracy: 0.5123\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6526 - accuracy: 0.5361 - val_loss: 0.6992 - val_accuracy: 0.5133\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6519 - accuracy: 0.5386 - val_loss: 0.6967 - val_accuracy: 0.5125\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6513 - accuracy: 0.5389 - val_loss: 0.7038 - val_accuracy: 0.5149\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5bc22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 6ms/step - loss: 0.7015 - accuracy: 0.5172\n",
      "[0.7014786005020142, 0.5171599984169006]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=1)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c066b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a455e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b05197a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0f3e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e27dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d5646bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00077586, -0.02224468,  0.07337296,  0.07552832,  0.07973547,\n",
       "       -0.07544058,  0.00706407,  0.0208412 , -0.06673347,  0.07029911,\n",
       "       -0.05000719, -0.09548017, -0.00753208,  0.01605638, -0.07532943,\n",
       "        0.02395668], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf5010",
   "metadata": {},
   "source": [
    "### 워드 임베딩 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d0fba14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('his', 0.7920361161231995),\n",
       " (\"isn't\", 0.7812005281448364),\n",
       " ('2009', 0.7777510285377502),\n",
       " ('revive', 0.7755345702171326),\n",
       " ('consequence', 0.7716487050056458),\n",
       " ('maker', 0.7626373767852783),\n",
       " ('praying', 0.7596304416656494),\n",
       " ('using', 0.7536416053771973),\n",
       " ('faced', 0.7375809550285339),\n",
       " ('tarzan', 0.7357887029647827)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f5f32",
   "metadata": {},
   "source": [
    "우리가 다룬 정도의 훈련 데이터로는 워드 벡터를 정교하게 학습시키기 어렵습니다.\n",
    "그래서 이번에는 구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 가져다 활용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed880df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b0073",
   "metadata": {},
   "source": [
    "### 워드 임베딩 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72ee45e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de01c37",
   "metadata": {},
   "source": [
    "### 임베딩 레이어를 word2vec으로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3621341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b07d4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5aabfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 84ms/step - loss: 0.6826 - accuracy: 0.5592 - val_loss: 0.6665 - val_accuracy: 0.5963\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.6206 - accuracy: 0.6681 - val_loss: 0.5761 - val_accuracy: 0.7161\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.4552 - accuracy: 0.8000 - val_loss: 0.4084 - val_accuracy: 0.8167\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.3054 - accuracy: 0.8755 - val_loss: 0.3303 - val_accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.2227 - accuracy: 0.9172 - val_loss: 0.3114 - val_accuracy: 0.8692\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.1759 - accuracy: 0.9381 - val_loss: 0.3431 - val_accuracy: 0.8559\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.1293 - accuracy: 0.9611 - val_loss: 0.3238 - val_accuracy: 0.8722\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0914 - accuracy: 0.9781 - val_loss: 0.3243 - val_accuracy: 0.8733\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0654 - accuracy: 0.9871 - val_loss: 0.3543 - val_accuracy: 0.8685\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0453 - accuracy: 0.9937 - val_loss: 0.3561 - val_accuracy: 0.8755\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0303 - accuracy: 0.9975 - val_loss: 0.3769 - val_accuracy: 0.8737\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0211 - accuracy: 0.9990 - val_loss: 0.3954 - val_accuracy: 0.8733\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0158 - accuracy: 0.9995 - val_loss: 0.4223 - val_accuracy: 0.8698\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0110 - accuracy: 0.9997 - val_loss: 0.4341 - val_accuracy: 0.8732\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0082 - accuracy: 0.9998 - val_loss: 0.4454 - val_accuracy: 0.8748\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0062 - accuracy: 0.9999 - val_loss: 0.4611 - val_accuracy: 0.8753\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.4737 - val_accuracy: 0.8734\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.4869 - val_accuracy: 0.8740\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.4997 - val_accuracy: 0.8728\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.5110 - val_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6370de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5456 - accuracy: 0.8606\n",
      "[0.5455783009529114, 0.8606399893760681]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f88b1",
   "metadata": {},
   "source": [
    "# 네이버 영화리뷰 감성분석 도전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ca8d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9cdae",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "581145e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3) (50000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8c177",
   "metadata": {},
   "source": [
    "* 데이터의 중복 제거\n",
    "* NaN 결측치 제거\n",
    "* 한국어 토크나이저로 토큰화\n",
    "* 불용어(Stopwords) 제거\n",
    "* 사전word_to_index 구성\n",
    "* 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "* X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7b90a",
   "metadata": {},
   "source": [
    "## 2) 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6e55f9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/4263070471.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(X_train_seq), np.array(y_train), np.array(X_test_seq), np.array(y_test), word_to_index\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']\n",
    "\n",
    "\n",
    "def preprocess(texts):\n",
    "    # 토큰화 및 불용어 제거\n",
    "    tokens = [token for text in texts for token in tokenizer.morphs(text) if token not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(tokens, num_words=None):\n",
    "    # 사전 구성\n",
    "    counter = Counter(tokens)\n",
    "    vocab = {\n",
    "        '<PAD>': 0,  # 패딩용 단어\n",
    "        '<BOS>': 1,  # 문장의 시작지점\n",
    "        '<UNK>': 2   # 사전에 없는(Unknown) 단어\n",
    "    }\n",
    "    if num_words:\n",
    "        most_common = counter.most_common(num_words - len(vocab))\n",
    "    else:\n",
    "        most_common = counter.most_common()\n",
    "    \n",
    "    for i, (word, _) in enumerate(most_common, start=len(vocab)):\n",
    "        vocab[word] = i\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def texts_to_sequences(texts, word_to_index):\n",
    "    # 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "    sequences = [[word_to_index.get(token, 0) for token in tokenizer.morphs(text)] for text in texts]\n",
    "    return sequences\n",
    "\n",
    "def load_data(train_data, test_data, num_words=None):\n",
    "    # 1. 중복 제거 및 NaN 결측치 제거\n",
    "    train_data = train_data.drop_duplicates().dropna().reset_index(drop=True)\n",
    "    test_data = test_data.drop_duplicates().dropna().reset_index(drop=True)\n",
    "    \n",
    "    # 2. 데이터 분리\n",
    "    X_train = train_data['document'].tolist()\n",
    "    y_train = train_data['label'].tolist()\n",
    "    X_test = test_data['document'].tolist()\n",
    "    y_test = test_data['label'].tolist()\n",
    "\n",
    "    # 3. 텍스트 전처리 (토큰화 및 불용어 제거)\n",
    "    train_tokens = preprocess(X_train)\n",
    "    test_tokens = preprocess(X_test)\n",
    "\n",
    "    # 4. 사전 구성\n",
    "    word_to_index = build_vocab(train_tokens, num_words)\n",
    "\n",
    "    # 5. 텍스트를 인덱스 시퀀스로 변환\n",
    "    X_train_seq = texts_to_sequences(X_train, word_to_index)\n",
    "    X_test_seq = texts_to_sequences(X_test, word_to_index)\n",
    "\n",
    "    return np.array(X_train_seq), np.array(y_train), np.array(X_test_seq), np.array(y_test), word_to_index\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data, num_words=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "19e6d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149995 49997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_train), len(X_test)) # 중복 제거 및 NaN 결측치 제거의 영향으로 판단됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3da865ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<BOS>': 1,\n",
       " '<UNK>': 2,\n",
       " '.': 3,\n",
       " '영화': 4,\n",
       " '다': 5,\n",
       " '고': 6,\n",
       " '하': 7,\n",
       " '을': 8,\n",
       " '보': 9,\n",
       " '..': 10,\n",
       " '게': 11,\n",
       " ',': 12,\n",
       " '!': 13,\n",
       " '지': 14,\n",
       " '있': 15,\n",
       " '없': 16,\n",
       " '?': 17,\n",
       " '좋': 18,\n",
       " '나': 19,\n",
       " '었': 20,\n",
       " '만': 21,\n",
       " '는데': 22,\n",
       " '너무': 23,\n",
       " '봤': 24,\n",
       " '적': 25,\n",
       " '안': 26,\n",
       " '정말': 27,\n",
       " '로': 28,\n",
       " '음': 29,\n",
       " '것': 30,\n",
       " '아': 31,\n",
       " '네요': 32,\n",
       " '재밌': 33,\n",
       " '어': 34,\n",
       " '점': 35,\n",
       " '같': 36,\n",
       " '지만': 37,\n",
       " '진짜': 38,\n",
       " '했': 39,\n",
       " '에서': 40,\n",
       " '기': 41,\n",
       " '네': 42,\n",
       " '않': 43,\n",
       " '거': 44,\n",
       " '았': 45,\n",
       " '수': 46,\n",
       " '되': 47,\n",
       " '면': 48,\n",
       " 'ㅋㅋ': 49,\n",
       " '말': 50,\n",
       " '연기': 51,\n",
       " '인': 52,\n",
       " '최고': 53,\n",
       " '주': 54,\n",
       " '내': 55,\n",
       " '~': 56,\n",
       " '평점': 57,\n",
       " '이런': 58,\n",
       " '어요': 59,\n",
       " '던': 60,\n",
       " '할': 61,\n",
       " '왜': 62,\n",
       " '1': 63,\n",
       " '겠': 64,\n",
       " '해': 65,\n",
       " '스토리': 66,\n",
       " '습니다': 67,\n",
       " 'ㅋㅋㅋ': 68,\n",
       " '...': 69,\n",
       " '드라마': 70,\n",
       " '생각': 71,\n",
       " '아니': 72,\n",
       " '더': 73,\n",
       " '그': 74,\n",
       " '싶': 75,\n",
       " '사람': 76,\n",
       " '듯': 77,\n",
       " '감동': 78,\n",
       " '때': 79,\n",
       " '함': 80,\n",
       " '배우': 81,\n",
       " '본': 82,\n",
       " '까지': 83,\n",
       " '뭐': 84,\n",
       " '볼': 85,\n",
       " '알': 86,\n",
       " '만들': 87,\n",
       " '내용': 88,\n",
       " '감독': 89,\n",
       " '보다': 90,\n",
       " '라': 91,\n",
       " '재미': 92,\n",
       " '그냥': 93,\n",
       " '지루': 94,\n",
       " '시간': 95,\n",
       " '재미있': 96,\n",
       " '중': 97,\n",
       " '년': 98,\n",
       " '잼': 99,\n",
       " '10': 100,\n",
       " '재미없': 101,\n",
       " '였': 102,\n",
       " '쓰레기': 103,\n",
       " '사랑': 104,\n",
       " '못': 105,\n",
       " '냐': 106,\n",
       " '서': 107,\n",
       " '2': 108,\n",
       " '라고': 109,\n",
       " '야': 110,\n",
       " '니': 111,\n",
       " '면서': 112,\n",
       " '번': 113,\n",
       " '다시': 114,\n",
       " '나오': 115,\n",
       " '작품': 116,\n",
       " '이거': 117,\n",
       " '하나': 118,\n",
       " '줄': 119,\n",
       " '해서': 120,\n",
       " '개': 121,\n",
       " '남': 122,\n",
       " '정도': 123,\n",
       " '마지막': 124,\n",
       " '끝': 125,\n",
       " '이건': 126,\n",
       " '임': 127,\n",
       " '액션': 128,\n",
       " 'ㅋ': 129,\n",
       " '3': 130,\n",
       " '입니다': 131,\n",
       " '기대': 132,\n",
       " '건': 133,\n",
       " '완전': 134,\n",
       " '라는': 135,\n",
       " '분': 136,\n",
       " '다는': 137,\n",
       " '참': 138,\n",
       " '많': 139,\n",
       " '아깝': 140,\n",
       " '처음': 141,\n",
       " '장면': 142,\n",
       " '대': 143,\n",
       " '다가': 144,\n",
       " '으면': 145,\n",
       " '지금': 146,\n",
       " '모르': 147,\n",
       " '이렇게': 148,\n",
       " \"'\": 149,\n",
       " '편': 150,\n",
       " '일': 151,\n",
       " '이게': 152,\n",
       " '돈': 153,\n",
       " '최악': 154,\n",
       " '성': 155,\n",
       " '느낌': 156,\n",
       " '시': 157,\n",
       " '이야기': 158,\n",
       " '별로': 159,\n",
       " '된': 160,\n",
       " '봐도': 161,\n",
       " '님': 162,\n",
       " '어서': 163,\n",
       " '애': 164,\n",
       " '전': 165,\n",
       " 'ㅠㅠ': 166,\n",
       " '넘': 167,\n",
       " '인데': 168,\n",
       " '다고': 169,\n",
       " '이해': 170,\n",
       " '명작': 171,\n",
       " '^^': 172,\n",
       " '그리고': 173,\n",
       " '역시': 174,\n",
       " '난': 175,\n",
       " '여자': 176,\n",
       " '또': 177,\n",
       " '이상': 178,\n",
       " '걸': 179,\n",
       " '한국': 180,\n",
       " '에게': 181,\n",
       " '는지': 182,\n",
       " '많이': 183,\n",
       " '부터': 184,\n",
       " '만든': 185,\n",
       " '주인공': 186,\n",
       " '받': 187,\n",
       " '합니다': 188,\n",
       " '!!': 189,\n",
       " '두': 190,\n",
       " '우리': 191,\n",
       " '살': 192,\n",
       " '괜찮': 193,\n",
       " '길': 194,\n",
       " '엔': 195,\n",
       " '기억': 196,\n",
       " '한다': 197,\n",
       " 'ㅎㅎ': 198,\n",
       " '연출': 199,\n",
       " '때문': 200,\n",
       " '이나': 201,\n",
       " '요': 202,\n",
       " '저': 203,\n",
       " '재': 204,\n",
       " '꼭': 205,\n",
       " '랑': 206,\n",
       " '며': 207,\n",
       " '현실': 208,\n",
       " 'ㅡㅡ': 209,\n",
       " '긴': 210,\n",
       " '무슨': 211,\n",
       " '마음': 212,\n",
       " '내내': 213,\n",
       " '굿': 214,\n",
       " '결말': 215,\n",
       " '죽': 216,\n",
       " '남자': 217,\n",
       " '세요': 218,\n",
       " '전개': 219,\n",
       " '속': 220,\n",
       " '소재': 221,\n",
       " '짱': 222,\n",
       " '인생': 223,\n",
       " '공포': 224,\n",
       " '다른': 225,\n",
       " '아서': 226,\n",
       " '씨': 227,\n",
       " '~~': 228,\n",
       " '짜증': 229,\n",
       " '은데': 230,\n",
       " '아요': 231,\n",
       " '뿐': 232,\n",
       " '필요': 233,\n",
       " '별': 234,\n",
       " '유치': 235,\n",
       " '가장': 236,\n",
       " '음악': 237,\n",
       " ')': 238,\n",
       " '일본': 239,\n",
       " '낮': 240,\n",
       " '아이': 241,\n",
       " ';;': 242,\n",
       " '오': 243,\n",
       " '반전': 244,\n",
       " '매력': 245,\n",
       " '수준': 246,\n",
       " '다니': 247,\n",
       " '밋': 248,\n",
       " '웃': 249,\n",
       " '맞': 250,\n",
       " '인지': 251,\n",
       " '가슴': 252,\n",
       " '없이': 253,\n",
       " '원작': 254,\n",
       " '높': 255,\n",
       " 'ㄷ': 256,\n",
       " '인간': 257,\n",
       " '데': 258,\n",
       " 'ㅠ': 259,\n",
       " '(': 260,\n",
       " '노': 261,\n",
       " '만드': 262,\n",
       " '급': 263,\n",
       " '눈물': 264,\n",
       " '준': 265,\n",
       " '보여': 266,\n",
       " '용': 267,\n",
       " '찍': 268,\n",
       " '인가': 269,\n",
       " '을까': 270,\n",
       " '코미디': 271,\n",
       " '마': 272,\n",
       " '화': 273,\n",
       " '신': 274,\n",
       " '여': 275,\n",
       " '모든': 276,\n",
       " '쓰': 277,\n",
       " '아직': 278,\n",
       " '5': 279,\n",
       " '추천': 280,\n",
       " '처럼': 281,\n",
       " '눈': 282,\n",
       " '아닌': 283,\n",
       " '자체': 284,\n",
       " '4': 285,\n",
       " '울': 286,\n",
       " '대박': 287,\n",
       " '몰입': 288,\n",
       " '몇': 289,\n",
       " '실망': 290,\n",
       " '스럽': 291,\n",
       " '는다': 292,\n",
       " '대한': 293,\n",
       " '죠': 294,\n",
       " '란': 295,\n",
       " '그런': 296,\n",
       " '솔직히': 297,\n",
       " 'ㅎ': 298,\n",
       " '캐릭터': 299,\n",
       " '아주': 300,\n",
       " '모두': 301,\n",
       " '-': 302,\n",
       " '가족': 303,\n",
       " '여운': 304,\n",
       " '건지': 305,\n",
       " '전혀': 306,\n",
       " '연기력': 307,\n",
       " '나라': 308,\n",
       " '후': 309,\n",
       " '다면': 310,\n",
       " '될': 311,\n",
       " '뭔가': 312,\n",
       " '그래도': 313,\n",
       " ';': 314,\n",
       " '시리즈': 315,\n",
       " '근데': 316,\n",
       " '작': 317,\n",
       " '표현': 318,\n",
       " '모습': 319,\n",
       " '공감': 320,\n",
       " '계속': 321,\n",
       " '먹': 322,\n",
       " '\"\"': 323,\n",
       " '제목': 324,\n",
       " '7': 325,\n",
       " '이랑': 326,\n",
       " '극장': 327,\n",
       " '치': 328,\n",
       " '비': 329,\n",
       " '이걸': 330,\n",
       " '진': 331,\n",
       " '바': 332,\n",
       " '0': 333,\n",
       " 'OO': 334,\n",
       " '그렇': 335,\n",
       " '대사': 336,\n",
       " '부분': 337,\n",
       " '개봉': 338,\n",
       " '대단': 339,\n",
       " '어디': 340,\n",
       " '된다': 341,\n",
       " '작가': 342,\n",
       " '기분': 343,\n",
       " '아쉽': 344,\n",
       " '제': 345,\n",
       " '진심': 346,\n",
       " '타임': 347,\n",
       " '/': 348,\n",
       " '놓': 349,\n",
       " '웃기': 350,\n",
       " '보이': 351,\n",
       " '해도': 352,\n",
       " '이제': 353,\n",
       " '물': 354,\n",
       " '봐야': 355,\n",
       " '막장': 356,\n",
       " '삶': 357,\n",
       " '친구': 358,\n",
       " '잔잔': 359,\n",
       " '씬': 360,\n",
       " '조금': 361,\n",
       " '딱': 362,\n",
       " '억지': 363,\n",
       " '영상': 364,\n",
       " '찾': 365,\n",
       " '요즘': 366,\n",
       " '같이': 367,\n",
       " '\"': 368,\n",
       " '중간': 369,\n",
       " '구': 370,\n",
       " '스릴러': 371,\n",
       " '라도': 372,\n",
       " '....': 373,\n",
       " '가지': 374,\n",
       " '8': 375,\n",
       " '믿': 376,\n",
       " '싫': 377,\n",
       " '아까운': 378,\n",
       " '나왔': 379,\n",
       " '점수': 380,\n",
       " '긴장감': 381,\n",
       " '부족': 382,\n",
       " '개인': 383,\n",
       " '제대로': 384,\n",
       " '노래': 385,\n",
       " '이유': 386,\n",
       " '만큼': 387,\n",
       " '라면': 388,\n",
       " '시작': 389,\n",
       " '구나': 390,\n",
       " '잇': 391,\n",
       " '특히': 392,\n",
       " '한테': 393,\n",
       " '날': 394,\n",
       " '아름다운': 395,\n",
       " '려고': 396,\n",
       " '제일': 397,\n",
       " '시대': 398,\n",
       " 'ㅜㅜ': 399,\n",
       " '어떻게': 400,\n",
       " '엔딩': 401,\n",
       " '당시': 402,\n",
       " '봐': 403,\n",
       " '하지만': 404,\n",
       " '나름': 405,\n",
       " '무섭': 406,\n",
       " '명': 407,\n",
       " '나온': 408,\n",
       " '해요': 409,\n",
       " '이것': 410,\n",
       " '사': 411,\n",
       " '오랜만': 412,\n",
       " '9': 413,\n",
       " '니까': 414,\n",
       " '팬': 415,\n",
       " '차라리': 416,\n",
       " '절대': 417,\n",
       " '세상': 418,\n",
       " '세': 419,\n",
       " '던데': 420,\n",
       " '의미': 421,\n",
       " '못하': 422,\n",
       " '따뜻': 423,\n",
       " '봄': 424,\n",
       " '욕': 425,\n",
       " '강추': 426,\n",
       " '훌륭': 427,\n",
       " '너무나': 428,\n",
       " 'ㅡ': 429,\n",
       " '감': 430,\n",
       " '됨': 431,\n",
       " '느끼': 432,\n",
       " '해야': 433,\n",
       " '빼': 434,\n",
       " '드': 435,\n",
       " '도대체': 436,\n",
       " '어야': 437,\n",
       " '답답': 438,\n",
       " '마다': 439,\n",
       " '준다': 440,\n",
       " '놈': 441,\n",
       " '글': 442,\n",
       " '전쟁': 443,\n",
       " '수작': 444,\n",
       " '설정': 445,\n",
       " '무엇': 446,\n",
       " '흥미': 447,\n",
       " '그저': 448,\n",
       " '만화': 449,\n",
       " '감정': 450,\n",
       " '미국': 451,\n",
       " '행복': 452,\n",
       " '신선': 453,\n",
       " '뻔': 454,\n",
       " '군': 455,\n",
       " '허접': 456,\n",
       " '형': 457,\n",
       " '앞': 458,\n",
       " '어도': 459,\n",
       " '관객': 460,\n",
       " '배경': 461,\n",
       " '시절': 462,\n",
       " '6': 463,\n",
       " '초반': 464,\n",
       " '사실': 465,\n",
       " '웃음': 466,\n",
       " 'OOO': 467,\n",
       " '엄청': 468,\n",
       " '답': 469,\n",
       " '더라': 470,\n",
       " '추억': 471,\n",
       " '라니': 472,\n",
       " '질': 473,\n",
       " '자신': 474,\n",
       " '캐스팅': 475,\n",
       " '류': 476,\n",
       " '첨': 477,\n",
       " '멋있': 478,\n",
       " '어색': 479,\n",
       " '시나리오': 480,\n",
       " '슬프': 481,\n",
       " '머': 482,\n",
       " '소름': 483,\n",
       " '밖에': 484,\n",
       " '정신': 485,\n",
       " '분위기': 486,\n",
       " '멋진': 487,\n",
       " '힘들': 488,\n",
       " '오늘': 489,\n",
       " '졸작': 490,\n",
       " '어이없': 491,\n",
       " '잡': 492,\n",
       " '봐서': 493,\n",
       " '킬링': 494,\n",
       " '위해': 495,\n",
       " '문제': 496,\n",
       " '구성': 497,\n",
       " '엄마': 498,\n",
       " '함께': 499,\n",
       " '이딴': 500,\n",
       " '잊': 501,\n",
       " '등': 502,\n",
       " '집': 503,\n",
       " '유쾌': 504,\n",
       " '뻔한': 505,\n",
       " '스러운': 506,\n",
       " '결국': 507,\n",
       " '낫': 508,\n",
       " '뭘': 509,\n",
       " '어떤': 510,\n",
       " '한데': 511,\n",
       " '나요': 512,\n",
       " '소리': 513,\n",
       " '간': 514,\n",
       " '역사': 515,\n",
       " '20': 516,\n",
       " '뭔': 517,\n",
       " '제발': 518,\n",
       " '포스터': 519,\n",
       " '아무리': 520,\n",
       " '코믹': 521,\n",
       " '!!!': 522,\n",
       " '완벽': 523,\n",
       " '~~~': 524,\n",
       " '애니메이션': 525,\n",
       " '맘': 526,\n",
       " '얼마나': 527,\n",
       " '난다': 528,\n",
       " '러': 529,\n",
       " '주연': 530,\n",
       " '원': 531,\n",
       " '♥': 532,\n",
       " '버리': 533,\n",
       " '어릴': 534,\n",
       " '후회': 535,\n",
       " '진부': 536,\n",
       " '나올': 537,\n",
       " '됐': 538,\n",
       " '장난': 539,\n",
       " '책': 540,\n",
       " '보단': 541,\n",
       " '큰': 542,\n",
       " '더니': 543,\n",
       " '영화관': 544,\n",
       " '개연': 545,\n",
       " '출연': 546,\n",
       " '둘': 547,\n",
       " '보고': 548,\n",
       " '극': 549,\n",
       " 'ㅅ': 550,\n",
       " '줬': 551,\n",
       " '밖': 552,\n",
       " '충격': 553,\n",
       " '여기': 554,\n",
       " '아름답': 555,\n",
       " '엇': 556,\n",
       " '잔인': 557,\n",
       " '얘기': 558,\n",
       " '평가': 559,\n",
       " '꺼': 560,\n",
       " '예술': 561,\n",
       " '매우': 562,\n",
       " '봐라': 563,\n",
       " '갈수록': 564,\n",
       " '든': 565,\n",
       " '이리': 566,\n",
       " '자기': 567,\n",
       " '위한': 568,\n",
       " '읽': 569,\n",
       " '이후': 570,\n",
       " '반': 571,\n",
       " '얼굴': 572,\n",
       " '꽤': 573,\n",
       " '낭비': 574,\n",
       " '티비': 575,\n",
       " '이쁘': 576,\n",
       " '옛날': 577,\n",
       " '으나': 578,\n",
       " '별점': 579,\n",
       " '깊': 580,\n",
       " '불쌍': 581,\n",
       " '불': 582,\n",
       " '못한': 583,\n",
       " '겟': 584,\n",
       " '시청': 585,\n",
       " '순수': 586,\n",
       " '라서': 587,\n",
       " '언제': 588,\n",
       " '건가': 589,\n",
       " '비디오': 590,\n",
       " '머리': 591,\n",
       " '애니': 592,\n",
       " '장르': 593,\n",
       " '텐데': 594,\n",
       " '+': 595,\n",
       " '생각나': 596,\n",
       " '배': 597,\n",
       " '미': 598,\n",
       " ':': 599,\n",
       " '그래서': 600,\n",
       " '다운': 601,\n",
       " '주제': 602,\n",
       " '다큐': 603,\n",
       " '다음': 604,\n",
       " '궁금': 605,\n",
       " '아님': 606,\n",
       " '시키': 607,\n",
       " '그렇게': 608,\n",
       " '누구': 609,\n",
       " '예전': 610,\n",
       " '크': 611,\n",
       " '그만': 612,\n",
       " '동안': 613,\n",
       " '뒤': 614,\n",
       " '??': 615,\n",
       " '인상': 616,\n",
       " '상황': 617,\n",
       " '이름': 618,\n",
       " '감사': 619,\n",
       " '미친': 620,\n",
       " '스릴': 621,\n",
       " '아무': 622,\n",
       " '시즌': 623,\n",
       " '오래': 624,\n",
       " '너': 625,\n",
       " 'B': 626,\n",
       " '집중': 627,\n",
       " '힘': 628,\n",
       " '그러': 629,\n",
       " '어느': 630,\n",
       " '본다': 631,\n",
       " '로맨스': 632,\n",
       " '진정': 633,\n",
       " '약간': 634,\n",
       " '나와서': 635,\n",
       " '식': 636,\n",
       " '마세요': 637,\n",
       " '까': 638,\n",
       " '방송': 639,\n",
       " '그나마': 640,\n",
       " '짜리': 641,\n",
       " '평': 642,\n",
       " '꿈': 643,\n",
       " '소설': 644,\n",
       " '여주인공': 645,\n",
       " '걸작': 646,\n",
       " '에요': 647,\n",
       " '몰': 648,\n",
       " '존나': 649,\n",
       " '그대로': 650,\n",
       " '죽이': 651,\n",
       " '인물': 652,\n",
       " '났': 653,\n",
       " '그것': 654,\n",
       " '회': 655,\n",
       " '떨어지': 656,\n",
       " '케': 657,\n",
       " '왔': 658,\n",
       " '만점': 659,\n",
       " '실화': 660,\n",
       " '대체': 661,\n",
       " '해라': 662,\n",
       " '훨씬': 663,\n",
       " '짓': 664,\n",
       " '~!': 665,\n",
       " '무': 666,\n",
       " '발연기': 667,\n",
       " '사회': 668,\n",
       " '전체': 669,\n",
       " '구만': 670,\n",
       " 'ㅜ': 671,\n",
       " '비슷': 672,\n",
       " '누가': 673,\n",
       " '30': 674,\n",
       " '막': 675,\n",
       " '끝나': 676,\n",
       " '햇': 677,\n",
       " '엉성': 678,\n",
       " 'CG': 679,\n",
       " '귀엽': 680,\n",
       " '여주': 681,\n",
       " '단': 682,\n",
       " '영상미': 683,\n",
       " '중국': 684,\n",
       " '초딩': 685,\n",
       " '비교': 686,\n",
       " '감성': 687,\n",
       " '네이버': 688,\n",
       " '세계': 689,\n",
       " '꿀': 690,\n",
       " '여배우': 691,\n",
       " '는가': 692,\n",
       " '더럽': 693,\n",
       " '망': 694,\n",
       " 'ㅎㅎㅎ': 695,\n",
       " '순간': 696,\n",
       " '느껴': 697,\n",
       " '려는': 698,\n",
       " ';;;': 699,\n",
       " '나이': 700,\n",
       " '상': 701,\n",
       " '대해': 702,\n",
       " '첫': 703,\n",
       " '어렸': 704,\n",
       " '생': 705,\n",
       " '쯤': 706,\n",
       " '판': 707,\n",
       " '입': 708,\n",
       " '돋': 709,\n",
       " '갔': 710,\n",
       " '가능': 711,\n",
       " '어설픈': 712,\n",
       " '셨': 713,\n",
       " '학교': 714,\n",
       " '100': 715,\n",
       " '성룡': 716,\n",
       " '타': 717,\n",
       " '혼자': 718,\n",
       " '아들': 719,\n",
       " '느낄': 720,\n",
       " '멋지': 721,\n",
       " '아야': 722,\n",
       " '졸': 723,\n",
       " '.....': 724,\n",
       " '어린': 725,\n",
       " '바로': 726,\n",
       " '나가': 727,\n",
       " '교훈': 728,\n",
       " '잘못': 729,\n",
       " '굳': 730,\n",
       " '한마디': 731,\n",
       " '맛': 732,\n",
       " '길래': 733,\n",
       " '존': 734,\n",
       " '판타지': 735,\n",
       " '딸': 736,\n",
       " '당신': 737,\n",
       " '화려': 738,\n",
       " '끌': 739,\n",
       " '티': 740,\n",
       " '삼류': 741,\n",
       " '아까움': 742,\n",
       " '잠': 743,\n",
       " '땜': 744,\n",
       " '든다': 745,\n",
       " '차': 746,\n",
       " '달': 747,\n",
       " '똥': 748,\n",
       " '맨': 749,\n",
       " '빨리': 750,\n",
       " '목소리': 751,\n",
       " '영': 752,\n",
       " '당': 753,\n",
       " '거의': 754,\n",
       " '나온다': 755,\n",
       " '듣': 756,\n",
       " '전부': 757,\n",
       " '봤었': 758,\n",
       " 'ㅉㅉ': 759,\n",
       " '독특': 760,\n",
       " '다르': 761,\n",
       " '가치': 762,\n",
       " '건데': 763,\n",
       " '초': 764,\n",
       " '어른': 765,\n",
       " '위': 766,\n",
       " '률': 767,\n",
       " '상당히': 768,\n",
       " '씩': 769,\n",
       " '90': 770,\n",
       " '다만': 771,\n",
       " '질질': 772,\n",
       " '넣': 773,\n",
       " '아버지': 774,\n",
       " '평론가': 775,\n",
       " '갑자기': 776,\n",
       " '줄거리': 777,\n",
       " '한번': 778,\n",
       " '이번': 779,\n",
       " '스타일': 780,\n",
       " '이러': 781,\n",
       " '그러나': 782,\n",
       " '여러': 783,\n",
       " '군요': 784,\n",
       " 'ㅂ': 785,\n",
       " '의도': 786,\n",
       " '저런': 787,\n",
       " '존재': 788,\n",
       " '밑': 789,\n",
       " '허무': 790,\n",
       " '%': 791,\n",
       " '부': 792,\n",
       " '대로': 793,\n",
       " '에선': 794,\n",
       " '째': 795,\n",
       " '각본': 796,\n",
       " '성우': 797,\n",
       " '예상': 798,\n",
       " '지루함': 799,\n",
       " '으면서': 800,\n",
       " '버린': 801,\n",
       " '그녀': 802,\n",
       " '너무너무': 803,\n",
       " '화면': 804,\n",
       " 'ㄱ': 805,\n",
       " '떠나': 806,\n",
       " '예쁘': 807,\n",
       " '비해': 808,\n",
       " '자연': 809,\n",
       " '담': 810,\n",
       " '평범': 811,\n",
       " '굉장히': 812,\n",
       " '그런지': 813,\n",
       " '뻔하': 814,\n",
       " '만나': 815,\n",
       " '슬픈': 816,\n",
       " '돼': 817,\n",
       " '못했': 818,\n",
       " '복수': 819,\n",
       " '관람': 820,\n",
       " '일단': 821,\n",
       " '줌': 822,\n",
       " '스': 823,\n",
       " '단순': 824,\n",
       " '새로운': 825,\n",
       " '댓글': 826,\n",
       " '중요': 827,\n",
       " '낸': 828,\n",
       " '피': 829,\n",
       " '앗': 830,\n",
       " '극장판': 831,\n",
       " '갖': 832,\n",
       " '제작': 833,\n",
       " '버렸': 834,\n",
       " '만족': 835,\n",
       " '쉽': 836,\n",
       " '선택': 837,\n",
       " '진행': 838,\n",
       " '아빠': 839,\n",
       " '쓴': 840,\n",
       " 'TV': 841,\n",
       " '요소': 842,\n",
       " '거나': 843,\n",
       " '한편': 844,\n",
       " '불편': 845,\n",
       " '항상': 846,\n",
       " '거기': 847,\n",
       " '연출력': 848,\n",
       " '그때': 849,\n",
       " '잃': 850,\n",
       " '롭': 851,\n",
       " '한다는': 852,\n",
       " '에로': 853,\n",
       " '산': 854,\n",
       " '탄탄': 855,\n",
       " '발': 856,\n",
       " '예요': 857,\n",
       " '나옴': 858,\n",
       " '한심': 859,\n",
       " '흥행': 860,\n",
       " '물론': 861,\n",
       " '려': 862,\n",
       " '지나': 863,\n",
       " '따라': 864,\n",
       " '전형': 865,\n",
       " '점점': 866,\n",
       " '이하': 867,\n",
       " '관계': 868,\n",
       " '역대': 869,\n",
       " '편집': 870,\n",
       " '조': 871,\n",
       " '아까워': 872,\n",
       " '짧': 873,\n",
       " '법': 874,\n",
       " '던가': 875,\n",
       " '총': 876,\n",
       " '따': 877,\n",
       " '충분히': 878,\n",
       " '안타깝': 879,\n",
       " '에겐': 880,\n",
       " '아닌가': 881,\n",
       " '화이팅': 882,\n",
       " '식상': 883,\n",
       " 'tv': 884,\n",
       " '80': 885,\n",
       " '몰랐': 886,\n",
       " '김': 887,\n",
       " '자꾸': 888,\n",
       " '훈훈': 889,\n",
       " '미안': 890,\n",
       " '-_-': 891,\n",
       " '도록': 892,\n",
       " '게임': 893,\n",
       " '멜': 894,\n",
       " '장': 895,\n",
       " '원래': 896,\n",
       " '곳': 897,\n",
       " '그게': 898,\n",
       " '자극': 899,\n",
       " '몸': 900,\n",
       " '삼': 901,\n",
       " '손': 902,\n",
       " '~!!': 903,\n",
       " '구요': 904,\n",
       " '나쁜': 905,\n",
       " '어쩔': 906,\n",
       " '사건': 907,\n",
       " '설명': 908,\n",
       " '간다': 909,\n",
       " '팔': 910,\n",
       " '똑같': 911,\n",
       " '뭔지': 912,\n",
       " '풀': 913,\n",
       " '잖아': 914,\n",
       " '어울리': 915,\n",
       " '짜': 916,\n",
       " '귀신': 917,\n",
       " '짐': 918,\n",
       " '과거': 919,\n",
       " '빙': 920,\n",
       " '노력': 921,\n",
       " '그래픽': 922,\n",
       " '황당': 923,\n",
       " '도저히': 924,\n",
       " '조차': 925,\n",
       " '닿': 926,\n",
       " '됬': 927,\n",
       " '아프': 928,\n",
       " '중반': 929,\n",
       " '빠': 930,\n",
       " '개그': 931,\n",
       " '죽음': 932,\n",
       " '듬': 933,\n",
       " '프랑스': 934,\n",
       " '코메디': 935,\n",
       " '미치': 936,\n",
       " '홍콩': 937,\n",
       " '취향': 938,\n",
       " '빠져': 939,\n",
       " '속편': 940,\n",
       " '했었': 941,\n",
       " '역': 942,\n",
       " '무비': 943,\n",
       " '무조건': 944,\n",
       " '짱짱': 945,\n",
       " '소중': 946,\n",
       " '헐': 947,\n",
       " '이란': 948,\n",
       " '프로': 949,\n",
       " '멋': 950,\n",
       " '참신': 951,\n",
       " 'good': 952,\n",
       " '쳐': 953,\n",
       " '병맛': 954,\n",
       " '나쁘': 955,\n",
       " '좋아하': 956,\n",
       " '특유': 957,\n",
       " '비추': 958,\n",
       " '아쉬운': 959,\n",
       " '괜히': 960,\n",
       " '빠지': 961,\n",
       " '척': 962,\n",
       " '더욱': 963,\n",
       " '넘치': 964,\n",
       " '진지': 965,\n",
       " '리': 966,\n",
       " '또한': 967,\n",
       " '유명': 968,\n",
       " '상상': 969,\n",
       " '숨': 970,\n",
       " '상영': 971,\n",
       " '결혼': 972,\n",
       " '전설': 973,\n",
       " 'ost': 974,\n",
       " '심리': 975,\n",
       " '무서운': 976,\n",
       " '엄청난': 977,\n",
       " '인듯': 978,\n",
       " '희망': 979,\n",
       " '오히려': 980,\n",
       " '예고편': 981,\n",
       " '별루': 982,\n",
       " '후반부': 983,\n",
       " '아저씨': 984,\n",
       " '틀': 985,\n",
       " '더빙': 986,\n",
       " '으니': 987,\n",
       " '고자': 988,\n",
       " '왕': 989,\n",
       " '심하': 990,\n",
       " '바보': 991,\n",
       " '연기자': 992,\n",
       " 'ㄴ': 993,\n",
       " '쩔': 994,\n",
       " '촬영': 995,\n",
       " '그리': 996,\n",
       " '소녀': 997,\n",
       " '느꼈': 998,\n",
       " '끝내': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "65a0427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e8369502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "efe79561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 4, 27, 2], [1, 27, 2, 2]]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"이 영화 정말 재미있어요\", \"정말 재미없는 영화였어요\"]\n",
    "get_encoded_sentences(sentences, word_to_index) # [[1, 2, 4, 27, 2], [1, 27, 2, 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0b9cf402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<UNK> 영화 정말 <UNK>', '정말 <UNK> <UNK>']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences = [[1, 2, 4, 27, 2], [1, 27, 2, 2]]\n",
    "get_decoded_sentences(encoded_sentences, index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d12bd",
   "metadata": {},
   "source": [
    "## 3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "* 데이터셋 내 문장 길이 분포\n",
    "* 적절한 최대 문장 길이 지정\n",
    "* keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4f686996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  18.3542491699668\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  15.347552229578971\n",
      "pad_sequences maxlen :  55\n",
      "전체 문장의 0.9506380255210208%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2.4 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5b83e4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149995, 55) (49997, 55)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba1e42",
   "metadata": {},
   "source": [
    "## 4) 모델 구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e23a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 16)          16000000  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 16,000,881\n",
      "Trainable params: 16,000,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000000    # 어휘 사전의 크기입니다\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f31cf",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c2130263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99995,)\n",
      "(99995,)\n"
     ]
    }
   ],
   "source": [
    "X_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "\n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "66435e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3240009608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m  \u001b[0;31m# 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = model.fit(partial_X_train,\n\u001b[0m\u001b[1;32m      8\u001b[0m                     \u001b[0mpartial_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                **kwargs):\n\u001b[1;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae8f49",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcbfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d82a4c81",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcf08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b363185",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선\n",
    "* 한국어 Word2Vec은 /data 폴더 안에 있는 word2vec_ko.model을 활용하세요.\n",
    "* 한국어 Word2Vec을 활용할 때는 load_word2vec_format() 형태가 아닌 load() 형태로 모델을 불러와주세요. 또한 모델을 활용할 때에는 아래 예시와 같이 .wv를 붙여서 활용합니다. 좀더 자세한 활용법에 대해선 다음 링크들을 참조해주세요. 참고 링크1, 참고 링크2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa173b",
   "metadata": {},
   "source": [
    "```\n",
    "# 예시 코드\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "vector = word_vectors.wv[‘끝’]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18faa6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ef312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ee515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
